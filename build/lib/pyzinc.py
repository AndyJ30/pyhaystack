#!python
# -*- coding: utf-8 -*-
"""
File : pyzinc.py (2.x)
Zinc parser

See http://www.project-haystack.org for more details

Project Haystack is an open source initiative to streamline working with data from the Internet of Things. We standardize semantic data models and web services with the goal of making it easier to unlock value from the vast quantity of data being generated by the smart devices that permeate our homes, buildings, factories, and cities. Applications include automation, control, energy, HVAC, lighting, and other environmental systems.

"""
__author__ = 'Christian Tremblay'
__version__ = '0.02'
__license__ = 'AFL'

import re
import pyhaystack as ph
import csv

class Histories():
    """
    This class gathers every histories on the Jace
    """
    def __init__(self, session):
        self.hisList = []
        requestHistories = "read?filter=his"
        his = {'name' : '',
               'id': ''
               }
        histories = session.getZinc(requestHistories)
        his_to_csv = histories.split('\n')[2:]
        #his_to_csv = histories.replace(u'\xb0','deg').split('\n')[2:]
        reader = unicode_csv_reader(his_to_csv)
        for lines in reader:
            print lines
            his['id'] = lines[4].split(' ')[0]
            his['name'] = lines[4].split(' ')[1]
            print 'Found %s, adding to list' % his['name']
            self.hisList.append(his)
            
    def getListofId(self):
        return self.hisList
    
class HistoryRecord():
    def __init__(self,session, zinc):
        self.data = []
        self.trend = {}
        for each in zinc:
            self.trend['ts']=each.split(',')[0]
            self.trend['val']=re.findall(r"[-+]?\d*\.\d+|\d+",each.split(',')[1])
            self.trend['unit']=re.findall(r"\W+",each.split(',')[1])
            self.data.append(self.trend)

        sefl.df = pd.DataFrame(self.data)
    
    def getDataFrame(self):
        return df
		
def unicode_csv_reader(unicode_csv_data, dialect=csv.excel, **kwargs):
    # csv.py doesn't do Unicode; encode temporarily as UTF-8:
    csv_reader = csv.reader(utf_8_encoder(unicode_csv_data),
                            dialect=dialect, **kwargs)
    for row in csv_reader:
        # decode UTF-8 back to Unicode, cell by cell:
        yield [unicode(cell, 'utf-8') for cell in row]

def utf_8_encoder(unicode_csv_data):
    for line in unicode_csv_data:
        yield line.encode('utf-8')